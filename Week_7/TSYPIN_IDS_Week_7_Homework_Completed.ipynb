{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset calling class as well as pandas\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "## load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "## create a pandas dataframe with the feature data and a series with the target\n",
    "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "y = pd.Series(housing.target, name='med_house_value')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dataset preview: \n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  \n",
      "0    -122.23  \n",
      "1    -122.22  \n",
      "2    -122.24  \n",
      "3    -122.25  \n",
      "4    -122.25  \n",
      "\n",
      "Target variable preview: \n",
      "0    4.526\n",
      "1    3.585\n",
      "2    3.521\n",
      "3    3.413\n",
      "4    3.422\n",
      "Name: med_house_value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## printing previews of the dataset and series using head()\n",
    "print(\"Feature dataset preview: \")\n",
    "print(X.head())\n",
    "print(\"\\nTarget variable preview: \")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature names along with number of missing values per feature: \n",
      "MedInc        0\n",
      "HouseAge      0\n",
      "AveRooms      0\n",
      "AveBedrms     0\n",
      "Population    0\n",
      "AveOccup      0\n",
      "Latitude      0\n",
      "Longitude     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# displaying number of missing values\n",
    "print(f\"\\nFeature names along with number of missing values per feature: \\n{X.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics of features: \n",
      "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
      "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
      "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
      "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
      "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
      "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
      "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
      "\n",
      "           AveOccup      Latitude     Longitude  \n",
      "count  20640.000000  20640.000000  20640.000000  \n",
      "mean       3.070655     35.631861   -119.569704  \n",
      "std       10.386050      2.135952      2.003532  \n",
      "min        0.692308     32.540000   -124.350000  \n",
      "25%        2.429741     33.930000   -121.800000  \n",
      "50%        2.818116     34.260000   -118.490000  \n",
      "75%        3.282261     37.710000   -118.010000  \n",
      "max     1243.333333     41.950000   -114.310000  \n",
      "\n",
      "Summary statistics of target variable: \n",
      "count    20640.000000\n",
      "mean         2.068558\n",
      "std          1.153956\n",
      "min          0.149990\n",
      "25%          1.196000\n",
      "50%          1.797000\n",
      "75%          2.647250\n",
      "max          5.000010\n",
      "Name: med_house_value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# displaying the summary statistics of the feature dataset and target variable\n",
    "print(f\"\\nSummary statistics of features: \\n{X.describe()}\")\n",
    "print(f\"\\nSummary statistics of target variable: \\n{y.describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary linear regression classes and functions\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "\n",
    "# use tts to split the data into training and testing sets\n",
    "X_train_raw, X_test_raw, y_train, y_test = tts(X, y, test_size=0.2, random_state=23)\n",
    "\n",
    "# creating a linear regression model and fitting it to the training data\n",
    "lin_reg_raw = lr()\n",
    "lin_reg_raw.fit(X_train_raw, y_train)\n",
    "\n",
    "# predicting the target variable using the test data\n",
    "y_pred_raw = lin_reg_raw.predict(X_test_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data Model:\n",
      "Mean Squared Error: 0.53\n",
      "Root Squared Error: 0.73\n",
      "R² Score: 0.61\n",
      "\n",
      "Model Coefficients: \n",
      "MedInc        0.436654\n",
      "HouseAge      0.009149\n",
      "AveRooms     -0.109385\n",
      "AveBedrms     0.616678\n",
      "Population   -0.000003\n",
      "AveOccup     -0.008606\n",
      "Latitude     -0.419646\n",
      "Longitude    -0.431455\n",
      "dtype: float64\n",
      "\n",
      "Model Intercept: \n",
      "0   -36.570768\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# importing necessary methods for evaluation of model\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, r2_score\n",
    "# evaluating the model using the mean squared error, root mean squared error, and R^2 score\n",
    "mse_raw = mean_squared_error(y_test, y_pred_raw)\n",
    "rmse_raw = root_mean_squared_error(y_test, y_pred_raw)\n",
    "r2_raw = r2_score(y_test, y_pred_raw)\n",
    "\n",
    "print(\"Raw Data Model:\")\n",
    "print(f\"Mean Squared Error: {mse_raw:.2f}\")\n",
    "print(f\"Root Squared Error: {rmse_raw:.2f}\")\n",
    "print(f\"R² Score: {r2_raw:.2f}\")\n",
    "\n",
    "print(\"\\nModel Coefficients: \")\n",
    "print(pd.Series(lin_reg_raw.coef_,\n",
    "                index=X.columns))\n",
    "print(\"\\nModel Intercept: \")\n",
    "print(pd.Series(lin_reg_raw.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Interpretation\n",
    "\n",
    "The R^2 score tells us that in our model about 61% of the variation in med_house_value, our target variable, is explained by the feature variables. This number doesn't actually tell us that much in a vacuum because different fields are differently stringent and sometimes people are looking for causation more than correlation. However, with the amount of seemingly variables we have, this does seem kind of low and I am inclined to think it is not a great model.\n",
    "\n",
    "Based on the model's coefficients, the average amount of bedrooms feature seems to have the most impact on the prediction for median house value closely followed by the median income feature while the other features seem to have smaller impacts. Both these variables have a positive impact on the median house value, while the average amount of rooms feature has the largest negative effect while also being less in magnitude. The latitude and longitude values seem to indicate that location has an impact on the median house value but it may be more difficult to interpret intuitively. \n",
    "\n",
    "I think the predicted values may not match very well because the root MSE of 0.73 is considerably larger for the range of values med_house_value can be. This is around 1/7 of the range and almost 60% of the standard deviation. Overall, this means that the model is not trustworthy enough to give you a close prediction of the target variable. Some more context may be needed about the feature variables, but with this and a R^2 of 0.61, it does not seem that our model matches very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "\n",
    "The three features I am going to choose for my simplified model are AveBedrms, MedInc, and HouseAge. I am choosing the first two because the magnitude of their effects was the largest in the first model and intuitively I think they both make sense as factors in house value. Besides the location values, the next highest magnitude was AveRooms but I didn't want to include this because I think it may covary significantly with AveBedrms and may not tell us that much. So, because I thought it intuitively made more sense than the rest, I chouse HouseAge because surely wear and tear relates to value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify my new features in a list\n",
    "new_features =[\"AveBedrms\", \"MedInc\", \"HouseAge\"]\n",
    "\n",
    "# create a new feature dataset with only the new features\n",
    "X_new = pd.DataFrame(X[new_features])\n",
    "\n",
    "# split the new feature dataset into training and testing sets\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = tts(X_new, y, test_size=0.2, random_state=77)\n",
    "\n",
    "# initialize a new linear regression model and fit it to the training data\n",
    "lin_reg_new = lr()\n",
    "lin_reg_new.fit(X_train_new, y_train_new)\n",
    "\n",
    "# predict the target variable using the new test data\n",
    "y_pred_new = lin_reg_new.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Feature Model:\n",
      "Mean Squared Error: 0.66\n",
      "Root Squared Error: 0.81\n",
      "R² Score: 0.50\n",
      "\n",
      "New Model Coefficients: \n",
      "AveBedrms    0.025596\n",
      "MedInc       0.433447\n",
      "HouseAge     0.017980\n",
      "dtype: float64\n",
      "\n",
      "New Model Intercept: \n",
      "0   -0.150595\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# evaluate the new model using the mean squared error, root mean squared error, and R^2 score\n",
    "mse_new = mean_squared_error(y_test_new, y_pred_new)\n",
    "rmse_new = root_mean_squared_error(y_test_new, y_pred_new)\n",
    "r2_new = r2_score(y_test_new, y_pred_new)   \n",
    "\n",
    "print(\"\\nNew Feature Model:\")\n",
    "print(f\"Mean Squared Error: {mse_new:.2f}\")\n",
    "print(f\"Root Squared Error: {rmse_new:.2f}\")\n",
    "print(f\"R² Score: {r2_new:.2f}\")    \n",
    "\n",
    "print(\"\\nNew Model Coefficients: \")\n",
    "print(pd.Series(lin_reg_new.coef_,\n",
    "                index=X_new.columns))\n",
    "print(\"\\nNew Model Intercept: \")\n",
    "print(pd.Series(lin_reg_new.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My new model has a higher mean squared error and root squared error than the original model, so it even less accurately predicts the target variable. However, we do seem to have quieted out the noise by still keeping an R^2 score of 0.50 with only 3/8 of the original variables. I assume this means that I have chosen at least some of the most relevant variables. In terms of the coefficients, a very interesting observation is that the MedInc coefficient is virtually the exact same, perhaps showing it is truly related to the target variable in this way. However, in this model we see AveBedrms have a much smaller impact than in the first model, while HouseAge is still not a huge impact but has doubled in magnitude. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 Interpretation\n",
    "\n",
    "The simplified model does not seem to really do a good job either, even performing worse in predictiveness. I think it does get rid of some unnecessary features but there may still be other confounding variables. It explains less of the variation and has a higher MSE and RMSE. I would not use this model in practice because I chose the variables based on prior coefficients and intuition and there are better ways to determine relevant variables to a model. I think it doesn't really do a better job at predicting the target variable or explaining relationships than the first model. However, I do like having less variables because this means the model is less likely to overfit the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
