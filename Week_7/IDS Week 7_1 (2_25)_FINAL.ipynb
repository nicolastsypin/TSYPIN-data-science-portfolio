{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSYyrxq5csQJ"
   },
   "source": [
    "# Supervised Machine Learning: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvloYQVhZzGh"
   },
   "source": [
    "## Linear Regression: Unscaled vs. Scaled Data\n",
    "In this demo, we follow the ML process:\n",
    "1. **Remember:** Load and inspect the data.\n",
    "2. **Formulate:** Build a linear regression model first on raw (unscaled) data.\n",
    "3. **Predict:** Evaluate the model's performance.\n",
    "\n",
    "Then we apply feature scaling and rebuild the model to compare results.\n",
    "We use the Student Performance dataset from Kaggle to predict the \"Performance Index\" of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KR7yBXm0Hltx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: kaggle\n",
      "unzip:  cannot find or open student-performance-multiple-linear-regression.zip, student-performance-multiple-linear-regression.zip.zip or student-performance-multiple-linear-regression.zip.ZIP.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Student_Performance.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munzip student-performance-multiple-linear-regression.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Import dataframe\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStudent_Performance.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m df\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Student_Performance.csv'"
     ]
    }
   ],
   "source": [
    "# import neccesary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Download data from Kaggle\n",
    "!kaggle datasets download -d nikhil7280/student-performance-multiple-linear-regression\n",
    "!unzip student-performance-multiple-linear-regression.zip\n",
    "\n",
    "# Import dataframe\n",
    "df = pd.read_csv(\"Student_Performance.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsIxmUI-Wo0O"
   },
   "outputs": [],
   "source": [
    "# Convert extracurricular activities to numeric\n",
    "df[\"Extracurricular Activities\"] = df[\"Extracurricular Activities\"].map({\"Yes\":1, \"No\":0})\n",
    "\n",
    "# Define the features and target variable based on the dataset\n",
    "feature_vars = [\"Hours Studied\", \"Previous Scores\", \"Sleep Hours\",\n",
    "                \"Sample Question Papers Practiced\", \"Extracurricular Activities\"]\n",
    "X = pd.DataFrame(df[feature_vars])\n",
    "y = pd.Series(df[\"Performance Index\"]) # Target: Performance Index\n",
    "\n",
    "# Display a preview of the dataset\n",
    "print(\"Dataset preview:\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget variable preview:\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVk3NAYM5wbe"
   },
   "source": [
    "## Part 1: Linear Regression on Unscaled Data\n",
    "In this section, we build a [linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.fit) model on the raw data.\n",
    "This helps us see the effect of differing scales on the coefficients.\n",
    "We start by [spliting our data into training and testing sets](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xV6-TqL951SG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Split the raw data (80% training, 20% testing)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model on unscaled data\n",
    "lin_reg_raw = LinearRegression()\n",
    "lin_reg_raw.fit(X_train_raw, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_raw = lin_reg_raw.predict(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUb4UOJa6ALE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, r2_score\n",
    "\n",
    "# Evaluate model performance\n",
    "mse_raw = mean_squared_error(y_test, y_pred_raw)\n",
    "rmse_raw = root_mean_squared_error(y_test, y_pred_raw)\n",
    "\n",
    "r2_raw = r2_score(y_test, y_pred_raw)\n",
    "\n",
    "print(\"Unscaled Data Model:\")\n",
    "print(f\"Mean Squared Error: {mse_raw:.2f}\")\n",
    "print(f\"Root Squared Error: {rmse_raw:.2f}\")\n",
    "print(f\"R² Score: {r2_raw:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUldxWi0BKGl"
   },
   "source": [
    "### Notes on Unscaled Model:\n",
    "- **Coefficients (Unscaled):**\n",
    "    - Each coefficient represents the change in the Performance Index for a one-unit change in the respective feature, holding all other features constant.\n",
    "    - For example, if \"Hours Studied\" has a coefficient of 2.85, it implies that for each additional hour studied, the Performance Index increases by 2.85 points (assuming other factors remain constant).\n",
    "    - However, because features are in different units (e.g., hours vs. scores), comparing these coefficients directly may be misleading.\n",
    "\n",
    "- **R² Score:**\n",
    "    - This metric indicates the proportion of the variance in the target variable explained by the model.\n",
    "    - An R² close to 1 suggests a very good fit, while an R² near 0 indicates the model fails to capture much variance.\n",
    "\n",
    "- **MSE & RMSE:**\n",
    "    - MSE measures the average squared difference between actual and predicted values.\n",
    "    - RMSE, being the square root of MSE, gives an error metric in the same units as the target.\n",
    "    - Lower RMSE values indicate better predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZB2zO71yBHyG"
   },
   "outputs": [],
   "source": [
    "# View our model's coefficients\n",
    "print(\"Model Coefficients (Unscaled):\")\n",
    "print(pd.Series(lin_reg_raw.coef_,\n",
    "                index=X.columns))\n",
    "print(\"\\nModel Intercept (Unscaled):\")\n",
    "print(pd.Series(lin_reg_raw.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqTyCRrOSxTL"
   },
   "source": [
    "### Manually Computing a Prediction from Our Model\n",
    "- In this section, we'll calculate a predicted value by hand (i.e., by multiplying the model's coefficients by the original feature values and adding the intercept).\n",
    "- This mirrors exactly what the model does internally.\n",
    "\n",
    "- **Why is this helpful?**\n",
    "   - It reinforces how linear regression makes its predictions using the equation: `prediction = intercept + (coef_1 * x_1) + (coef_2 * x_2) + ...`\n",
    "   - It helps us see the individual impact of each feature on the final prediction.\n",
    "   - It confirms that the manual approach matches the `model.predict()` output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZ7xL8YDTYGd"
   },
   "source": [
    "#### 1. Extract the coefficients and intercept from our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uP4ggD8mRLby"
   },
   "outputs": [],
   "source": [
    "coef_series = pd.Series(lin_reg_raw.coef_, index=X.columns)\n",
    "intercept = lin_reg_raw.intercept_\n",
    "\n",
    "print(\"Coefficients (Unscaled):\")\n",
    "print(coef_series)\n",
    "print(\"\\nIntercept:\", intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IENlzHSLTV16"
   },
   "source": [
    "#### 2. Select a single row of our data (e.g., the second row)\n",
    "- We select only the columns that were used as features in our model.\n",
    "- The row's values represent the actual data for Hours Studied, Previous Scores, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PR91MrnMQuE7"
   },
   "outputs": [],
   "source": [
    "# This row's feature values will be multiplied by our coefficients.\n",
    "row_index = 1  # for demonstration\n",
    "row_features = X.iloc[row_index]  # features only\n",
    "print(\"Feature values (Row\", row_index, \"):\\n\", row_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31cUy0iJTpy5"
   },
   "source": [
    "#### 3. Compute the manual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHIjwmBvSTNz"
   },
   "outputs": [],
   "source": [
    "manual_prediction = (row_features * coef_series).sum() + intercept\n",
    "print(\"\\nManual Prediction for Row\", row_index, \":\", manual_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EMoNVUxTwSZ"
   },
   "source": [
    "**Explanation:**\n",
    "- We multiply each feature value by its corresponding coefficient and sum them up.\n",
    "- Then, we add the intercept.\n",
    "- This is precisely the linear regression equation:\n",
    "$$\n",
    "\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\n",
    "$$\n",
    "\n",
    "Where:\n",
    " - $\\beta_0$ is the intercept\n",
    " - $\\beta_i$ is the coefficient for feature $x_i$\n",
    "\n",
    " Thus, `manual_prediction` should match what the model would predict internally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcSqpjAUUygV"
   },
   "source": [
    "#### 4. Compare to `model.predict()` for confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1x95-XjDU0U4"
   },
   "outputs": [],
   "source": [
    "model_prediction = lin_reg_raw.predict([row_features])\n",
    "print(\"Model Prediction from lin_reg_raw.predict():\", model_prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3SQz1XiVQti"
   },
   "source": [
    "### **Observation:**\n",
    "- The `manual_prediction` and `model_prediction` should be nearly identical (up to minor floating-point differences).\n",
    "- If they match, we've confirmed our understanding of how the model uses coefficients and intercept to make a prediction.\n",
    "\n",
    "### Why This Matters\n",
    "- **Transparency:** It shows exactly how each feature influences the final predicted value.\n",
    "- **Verification:** Confirms our \"manual\" math aligns with the model's internal computation.\n",
    "- **Interpretability:** By inspecting the coefficients, we see which features have the biggest impact (positive or negative) on the Performance Index, and we can discuss whether the magnitudes make sense given the domain context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0u3A7-UF6Fa6"
   },
   "source": [
    "## Part 2: Linear Regression on Scaled Data\n",
    "Now we apply feature scaling using StandardScaler and rebuild the model.\n",
    "Scaling brings all features to a similar scale, which aids in the interpretation of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u891WVe05rk0"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler and apply it to the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Split the scaled data\n",
    "X_train_scaled, X_test_scaled, _, _ = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model on scaled data\n",
    "lin_reg_scaled = LinearRegression()\n",
    "lin_reg_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_scaled = lin_reg_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse_scaled = mean_squared_error(y_test, y_pred_scaled)\n",
    "r2_scaled = r2_score(y_test, y_pred_scaled)\n",
    "rmse_scaled = root_mean_squared_error(y_test, y_pred_raw)\n",
    "\n",
    "print(\"\\nScaled Data Model:\")\n",
    "print(f\"Mean Squared Error: {mse_scaled:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_scaled:.2f}\")\n",
    "print(f\"R² Score: {r2_scaled:.2f}\")\n",
    "print(\"Model Coefficients (Scaled):\")\n",
    "print(pd.Series(lin_reg_scaled.coef_, index=X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-_4BofGByvU"
   },
   "source": [
    "### Notes on Scaled Model:\n",
    "- **Coefficients (Scaled):**\n",
    "    - After scaling, each coefficient indicates the change in the Performance Index for a one standard deviation change in that feature.\n",
    "    - This standardization makes it easier to compare the relative importance of features.\n",
    "    - For example, a higher coefficient means that feature has a larger effect on the target, per standard deviation change.\n",
    "\n",
    "- **R² and RMSE Comparison:**\n",
    "    - Often the overall performance metrics (R² and RMSE) do not change dramatically after scaling for linear regression.\n",
    "    - However, scaling is essential for interpreting the model coefficients correctly, especially when features are on different scales.\n",
    "    - It is also a critical preprocessing step for many other algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSFowtR16PYv"
   },
   "source": [
    "# Conclusion\n",
    "In this demo, we:\n",
    "- Built and evaluated a linear regression model on unscaled data.\n",
    "- Re-trained the model after applying feature scaling.\n",
    "- Observed that while overall performance metrics (**MSE** and **R²**) may be similar, scaling is crucial for the interpretability of model coefficients and for ensuring that features contribute in a balanced way.\n",
    "  \n",
    "### Key Takeaways:\n",
    "- **Coefficients:** On unscaled data, coefficients are tied to the original units, which can be hard to compare.\n",
    "  After scaling, coefficients represent the effect of a one standard deviation change in the feature.\n",
    "- **R² Score:** Reflects the proportion of variance in the target variable explained by the model.\n",
    "- **MSE (and RMSE):** Lower values indicate better model performance; RMSE provides an error measure in the target's units.\n",
    "\n",
    "This process reflects the \"remember-formulate-predict\" approach in machine learning."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNuiLhwPXT2/9GOv6o92FK1",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
