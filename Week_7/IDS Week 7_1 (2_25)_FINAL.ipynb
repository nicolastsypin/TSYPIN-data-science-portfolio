{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSYyrxq5csQJ"
   },
   "source": [
    "# Supervised Machine Learning: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvloYQVhZzGh"
   },
   "source": [
    "## Linear Regression: Unscaled vs. Scaled Data\n",
    "In this demo, we follow the ML process:\n",
    "1. **Remember:** Load and inspect the data.\n",
    "2. **Formulate:** Build a linear regression model first on raw (unscaled) data.\n",
    "3. **Predict:** Evaluate the model's performance.\n",
    "\n",
    "Then we apply feature scaling and rebuild the model to compare results.\n",
    "We use the Student Performance dataset from Kaggle to predict the \"Performance Index\" of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KR7yBXm0Hltx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: kaggle\n",
      "unzip:  cannot find or open student-performance-multiple-linear-regression.zip, student-performance-multiple-linear-regression.zip.zip or student-performance-multiple-linear-regression.zip.ZIP.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Student_Performance.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munzip student-performance-multiple-linear-regression.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Import dataframe\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent_Performance.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m df\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Student_Performance.csv'"
     ]
    }
   ],
   "source": [
    "# import neccesary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Download data from Kaggle\n",
    "!kaggle datasets download -d nikhil7280/student-performance-multiple-linear-regression\n",
    "!unzip student-performance-multiple-linear-regression.zip\n",
    "\n",
    "# Import dataframe\n",
    "df = pd.read_csv(\"Student_Performance.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsIxmUI-Wo0O"
   },
   "outputs": [],
   "source": [
    "# Convert extracurricular activities to numeric\n",
    "df[\"Extracurricular Activities\"] = df[\"Extracurricular Activities\"].map({\"Yes\":1, \"No\":0})\n",
    "\n",
    "# Define the features and target variable based on the dataset\n",
    "feature_vars = [\"Hours Studied\", \"Previous Scores\", \"Sleep Hours\",\n",
    "                \"Sample Question Papers Practiced\", \"Extracurricular Activities\"]\n",
    "X = pd.DataFrame(df[feature_vars])\n",
    "y = pd.Series(df[\"Performance Index\"]) # Target: Performance Index\n",
    "\n",
    "# Display a preview of the dataset\n",
    "print(\"Dataset preview:\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget variable preview:\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVk3NAYM5wbe"
   },
   "source": [
    "## Part 1: Linear Regression on Unscaled Data\n",
    "In this section, we build a [linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.fit) model on the raw data.\n",
    "This helps us see the effect of differing scales on the coefficients.\n",
    "We start by [spliting our data into training and testing sets](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xV6-TqL951SG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Split the raw data (80% training, 20% testing)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model on unscaled data\n",
    "lin_reg_raw = LinearRegression()\n",
    "lin_reg_raw.fit(X_train_raw, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_raw = lin_reg_raw.predict(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUb4UOJa6ALE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, r2_score\n",
    "\n",
    "# Evaluate model performance\n",
    "mse_raw = mean_squared_error(y_test, y_pred_raw)\n",
    "rmse_raw = root_mean_squared_error(y_test, y_pred_raw)\n",
    "\n",
    "r2_raw = r2_score(y_test, y_pred_raw)\n",
    "\n",
    "print(\"Unscaled Data Model:\")\n",
    "print(f\"Mean Squared Error: {mse_raw:.2f}\")\n",
    "print(f\"Root Squared Error: {rmse_raw:.2f}\")\n",
    "print(f\"R² Score: {r2_raw:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUldxWi0BKGl"
   },
   "source": [
    "### Notes on Unscaled Model:\n",
    "- **Coefficients (Unscaled):**\n",
    "    - Each coefficient represents the change in the Performance Index for a one-unit change in the respective feature, holding all other features constant.\n",
    "    - For example, if \"Hours Studied\" has a coefficient of 2.85, it implies that for each additional hour studied, the Performance Index increases by 2.85 points (assuming other factors remain constant).\n",
    "    - However, because features are in different units (e.g., hours vs. scores), comparing these coefficients directly may be misleading.\n",
    "\n",
    "- **R² Score:**\n",
    "    - This metric indicates the proportion of the variance in the target variable explained by the model.\n",
    "    - An R² close to 1 suggests a very good fit, while an R² near 0 indicates the model fails to capture much variance.\n",
    "\n",
    "- **MSE & RMSE:**\n",
    "    - MSE measures the average squared difference between actual and predicted values.\n",
    "    - RMSE, being the square root of MSE, gives an error metric in the same units as the target.\n",
    "    - Lower RMSE values indicate better predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZB2zO71yBHyG"
   },
   "outputs": [],
   "source": [
    "# View our model's coefficients\n",
    "print(\"Model Coefficients (Unscaled):\")\n",
    "print(pd.Series(lin_reg_raw.coef_,\n",
    "                index=X.columns))\n",
    "print(\"\\nModel Intercept (Unscaled):\")\n",
    "print(pd.Series(lin_reg_raw.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqTyCRrOSxTL"
   },
   "source": [
    "### Manually Computing a Prediction from Our Model\n",
    "- In this section, we'll calculate a predicted value by hand (i.e., by multiplying the model's coefficients by the original feature values and adding the intercept).\n",
    "- This mirrors exactly what the model does internally.\n",
    "\n",
    "- **Why is this helpful?**\n",
    "   - It reinforces how linear regression makes its predictions using the equation: `prediction = intercept + (coef_1 * x_1) + (coef_2 * x_2) + ...`\n",
    "   - It helps us see the individual impact of each feature on the final prediction.\n",
    "   - It confirms that the manual approach matches the `model.predict()` output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZ7xL8YDTYGd"
   },
   "source": [
    "#### 1. Extract the coefficients and intercept from our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uP4ggD8mRLby"
   },
   "outputs": [],
   "source": [
    "coef_series = pd.Series(lin_reg_raw.coef_, index=X.columns)\n",
    "intercept = lin_reg_raw.intercept_\n",
    "\n",
    "print(\"Coefficients (Unscaled):\")\n",
    "print(coef_series)\n",
    "print(\"\\nIntercept:\", intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IENlzHSLTV16"
   },
   "source": [
    "#### 2. Select a single row of our data (e.g., the second row)\n",
    "- We select only the columns that were used as features in our model.\n",
    "- The row's values represent the actual data for Hours Studied, Previous Scores, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PR91MrnMQuE7"
   },
   "outputs": [],
   "source": [
    "# This row's feature values will be multiplied by our coefficients.\n",
    "row_index = 1  # for demonstration\n",
    "row_features = X.iloc[row_index]  # features only\n",
    "print(\"Feature values (Row\", row_index, \"):\\n\", row_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31cUy0iJTpy5"
   },
   "source": [
    "#### 3. Compute the manual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHIjwmBvSTNz"
   },
   "outputs": [],
   "source": [
    "manual_prediction = (row_features * coef_series).sum() + intercept\n",
    "print(\"\\nManual Prediction for Row\", row_index, \":\", manual_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EMoNVUxTwSZ"
   },
   "source": [
    "**Explanation:**\n",
    "- We multiply each feature value by its corresponding coefficient and sum them up.\n",
    "- Then, we add the intercept.\n",
    "- This is precisely the linear regression equation:\n",
    "$$\n",
    "\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\n",
    "$$\n",
    "\n",
    "Where:\n",
    " - $\\beta_0$ is the intercept\n",
    " - $\\beta_i$ is the coefficient for feature $x_i$\n",
    "\n",
    " Thus, `manual_prediction` should match what the model would predict internally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcSqpjAUUygV"
   },
   "source": [
    "#### 4. Compare to `model.predict()` for confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1x95-XjDU0U4"
   },
   "outputs": [],
   "source": [
    "model_prediction = lin_reg_raw.predict([row_features])\n",
    "print(\"Model Prediction from lin_reg_raw.predict():\", model_prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3SQz1XiVQti"
   },
   "source": [
    "### **Observation:**\n",
    "- The `manual_prediction` and `model_prediction` should be nearly identical (up to minor floating-point differences).\n",
    "- If they match, we've confirmed our understanding of how the model uses coefficients and intercept to make a prediction.\n",
    "\n",
    "### Why This Matters\n",
    "- **Transparency:** It shows exactly how each feature influences the final predicted value.\n",
    "- **Verification:** Confirms our \"manual\" math aligns with the model's internal computation.\n",
    "- **Interpretability:** By inspecting the coefficients, we see which features have the biggest impact (positive or negative) on the Performance Index, and we can discuss whether the magnitudes make sense given the domain context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0u3A7-UF6Fa6"
   },
   "source": [
    "## Part 2: Linear Regression on Scaled Data\n",
    "Now we apply feature scaling using StandardScaler and rebuild the model.\n",
    "Scaling brings all features to a similar scale, which aids in the interpretation of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u891WVe05rk0"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler and apply it to the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Split the scaled data\n",
    "X_train_scaled, X_test_scaled, _, _ = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model on scaled data\n",
    "lin_reg_scaled = LinearRegression()\n",
    "lin_reg_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_scaled = lin_reg_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse_scaled = mean_squared_error(y_test, y_pred_scaled)\n",
    "r2_scaled = r2_score(y_test, y_pred_scaled)\n",
    "rmse_scaled = root_mean_squared_error(y_test, y_pred_raw)\n",
    "\n",
    "print(\"\\nScaled Data Model:\")\n",
    "print(f\"Mean Squared Error: {mse_scaled:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_scaled:.2f}\")\n",
    "print(f\"R² Score: {r2_scaled:.2f}\")\n",
    "print(\"Model Coefficients (Scaled):\")\n",
    "print(pd.Series(lin_reg_scaled.coef_, index=X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-_4BofGByvU"
   },
   "source": [
    "### Notes on Scaled Model:\n",
    "- **Coefficients (Scaled):**\n",
    "    - After scaling, each coefficient indicates the change in the Performance Index for a one standard deviation change in that feature.\n",
    "    - This standardization makes it easier to compare the relative importance of features.\n",
    "    - For example, a higher coefficient means that feature has a larger effect on the target, per standard deviation change.\n",
    "\n",
    "- **R² and RMSE Comparison:**\n",
    "    - Often the overall performance metrics (R² and RMSE) do not change dramatically after scaling for linear regression.\n",
    "    - However, scaling is essential for interpreting the model coefficients correctly, especially when features are on different scales.\n",
    "    - It is also a critical preprocessing step for many other algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSFowtR16PYv"
   },
   "source": [
    "# Conclusion\n",
    "In this demo, we:\n",
    "- Built and evaluated a linear regression model on unscaled data.\n",
    "- Re-trained the model after applying feature scaling.\n",
    "- Observed that while overall performance metrics (**MSE** and **R²**) may be similar, scaling is crucial for the interpretability of model coefficients and for ensuring that features contribute in a balanced way.\n",
    "  \n",
    "### Key Takeaways:\n",
    "- **Coefficients:** On unscaled data, coefficients are tied to the original units, which can be hard to compare.\n",
    "  After scaling, coefficients represent the effect of a one standard deviation change in the feature.\n",
    "- **R² Score:** Reflects the proportion of variance in the target variable explained by the model.\n",
    "- **MSE (and RMSE):** Lower values indicate better model performance; RMSE provides an error measure in the target's units.\n",
    "\n",
    "This process reflects the \"remember-formulate-predict\" approach in machine learning."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNuiLhwPXT2/9GOv6o92FK1",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
